{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from resources import DEFAULT_PATHS\n",
    "\n",
    "from tf_train_loop import TWTrainer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "REWARD_DICT = {\n",
    "    \"win_lose_value\": 100,\n",
    "    \"max_loop_pun\": 1,\n",
    "    \"change_reward\": 0,\n",
    "    \"useless_act_pun\": 1,\n",
    "    \"verb_in_adm\": 0,\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "DEFAULT_HP = {\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"initial_collect_steps\": 10000,\n",
    "    \"collect_steps_per_iteration\": 1,\n",
    "    \"replay_buffer_max_length\": 100000,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_eval_episodes\": 1,\n",
    "    \"game_gen_buffer\": 25,\n",
    "    \"num_eval_games\": 10,\n",
    "}\n",
    "\n",
    "trainer = TWTrainer(\n",
    "    env_dir=\"train_games_lvl1\",\n",
    "    reward_dict=REWARD_DICT,\n",
    "    hpar=DEFAULT_HP,\n",
    "    debug=False,\n",
    "    biased_buffer=False,\n",
    "    # embedding into fc is default policy\n",
    "    agent_label=\"FCPolicy\"\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "log can be found in/home/florian/Documents/DeepLearningNLP/resources/logdir/20210805-205306\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print(f\"Starting with lvl: 1 \\n\")\n",
    "\n",
    "eval_scores = trainer.train(\n",
    "    num_iterations=15000,\n",
    "    log_interval=250,\n",
    "    eval_interval=500,\n",
    "    game_gen_interval=500,\n",
    "    rndm_fill_replay=True,\n",
    "    plot_avg_ret=True,\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting with lvl: 1 \n",
      "\n",
      "WARNING:tensorflow:From /home/florian/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:382: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:From /home/florian/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:382: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/florian/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:From /home/florian/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step = 250: loss = 1.97e-02, Buff-len = 10350\n",
      "step = 500: loss = 5.14e-02, Buff-len = 10600\n",
      "step = 500: Average Return = -64.1\n",
      "step = 750: loss = 5.07e+06, Buff-len = 10850\n",
      "step = 1000: loss = 1.13e+09, Buff-len = 11100\n",
      "step = 1000: Average Return = -99.0\n",
      "step = 1250: loss = 5.42e+09, Buff-len = 11350\n",
      "step = 1500: loss = 1.30e+10, Buff-len = 11600\n",
      "step = 1500: Average Return = -99.0\n",
      "step = 1750: loss = 2.78e+10, Buff-len = 11850\n",
      "step = 2000: loss = 4.77e+10, Buff-len = 12100\n",
      "step = 2000: Average Return = -99.0\n",
      "step = 2250: loss = 7.57e+10, Buff-len = 12350\n",
      "step = 2500: loss = 2.50e+11, Buff-len = 12600\n",
      "step = 2500: Average Return = -99.0\n",
      "step = 2750: loss = 1.65e+10, Buff-len = 12850\n",
      "step = 3000: loss = 2.72e+10, Buff-len = 13100\n",
      "step = 3000: Average Return = -99.0\n",
      "step = 3250: loss = 6.50e+09, Buff-len = 13350\n",
      "step = 3500: loss = 1.22e+10, Buff-len = 13600\n",
      "step = 3500: Average Return = -99.0\n",
      "step = 3750: loss = 1.63e+10, Buff-len = 13850\n",
      "step = 4000: loss = 1.97e+10, Buff-len = 14100\n",
      "step = 4000: Average Return = -99.0\n",
      "step = 4250: loss = 8.88e+09, Buff-len = 14350\n",
      "step = 4500: loss = 6.48e+10, Buff-len = 14600\n",
      "step = 4500: Average Return = -99.0\n",
      "step = 4750: loss = 4.04e+10, Buff-len = 14850\n",
      "step = 5000: loss = 1.21e+10, Buff-len = 15100\n",
      "step = 5000: Average Return = -99.0\n",
      "step = 5250: loss = 1.83e+10, Buff-len = 15350\n",
      "step = 5500: loss = 4.35e+10, Buff-len = 15600\n",
      "step = 5500: Average Return = -99.0\n",
      "step = 5750: loss = 6.69e+10, Buff-len = 15850\n",
      "step = 6000: loss = 6.93e+10, Buff-len = 16100\n",
      "step = 6000: Average Return = -99.0\n",
      "step = 6250: loss = 2.44e+10, Buff-len = 16350\n",
      "step = 6500: loss = 7.39e+09, Buff-len = 16600\n",
      "step = 6500: Average Return = -99.0\n",
      "step = 6750: loss = 3.16e+09, Buff-len = 16850\n",
      "step = 7000: loss = 2.44e+10, Buff-len = 17100\n",
      "step = 7000: Average Return = -99.0\n",
      "step = 7250: loss = 5.23e+09, Buff-len = 17350\n",
      "step = 7500: loss = 2.10e+10, Buff-len = 17600\n",
      "step = 7500: Average Return = -99.0\n",
      "step = 7750: loss = 2.52e+10, Buff-len = 17850\n",
      "step = 8000: loss = 3.47e+10, Buff-len = 18100\n",
      "step = 8000: Average Return = -99.0\n",
      "step = 8250: loss = 1.53e+10, Buff-len = 18350\n",
      "step = 8500: loss = 1.32e+10, Buff-len = 18600\n",
      "step = 8500: Average Return = -94.0\n",
      "step = 8750: loss = 1.02e+10, Buff-len = 18850\n",
      "step = 9000: loss = 1.06e+10, Buff-len = 19100\n",
      "step = 9000: Average Return = -99.0\n",
      "step = 9250: loss = 7.69e+09, Buff-len = 19350\n",
      "step = 9500: loss = 6.37e+09, Buff-len = 19600\n",
      "step = 9500: Average Return = -99.0\n",
      "step = 9750: loss = 4.90e+09, Buff-len = 19850\n",
      "step = 10000: loss = 6.28e+09, Buff-len = 20100\n",
      "step = 10000: Average Return = -99.0\n",
      "step = 10250: loss = 6.03e+09, Buff-len = 20350\n",
      "step = 10500: loss = 4.52e+09, Buff-len = 20600\n",
      "step = 10500: Average Return = -99.0\n",
      "step = 10750: loss = 5.46e+09, Buff-len = 20850\n",
      "step = 11000: loss = 5.01e+09, Buff-len = 21100\n",
      "step = 11000: Average Return = -99.0\n",
      "step = 11250: loss = 4.64e+09, Buff-len = 21350\n",
      "step = 11500: loss = 4.90e+09, Buff-len = 21600\n",
      "step = 11500: Average Return = -99.0\n",
      "step = 11750: loss = 4.65e+09, Buff-len = 21850\n",
      "step = 12000: loss = 4.36e+09, Buff-len = 22100\n",
      "step = 12000: Average Return = -99.0\n",
      "step = 12250: loss = 4.09e+09, Buff-len = 22350\n",
      "step = 12500: loss = 3.01e+09, Buff-len = 22600\n",
      "step = 12500: Average Return = -94.0\n",
      "step = 12750: loss = 3.09e+09, Buff-len = 22850\n",
      "step = 13000: loss = 3.08e+09, Buff-len = 23100\n",
      "step = 13000: Average Return = -99.0\n",
      "step = 13250: loss = 3.18e+09, Buff-len = 23350\n",
      "step = 13500: loss = 3.39e+09, Buff-len = 23600\n",
      "step = 13500: Average Return = -99.0\n",
      "step = 13750: loss = 2.95e+09, Buff-len = 23850\n",
      "step = 14000: loss = 2.45e+09, Buff-len = 24100\n",
      "step = 14000: Average Return = -99.0\n",
      "step = 14250: loss = 1.57e+09, Buff-len = 24350\n",
      "step = 14500: loss = 1.65e+09, Buff-len = 24600\n",
      "step = 14500: Average Return = -99.0\n",
      "step = 14750: loss = 1.14e+09, Buff-len = 24850\n",
      "step = 15000: loss = 1.12e+09, Buff-len = 25100\n",
      "step = 15000: Average Return = -94.0\n",
      "(30,) [  500  1000  1500  2000  2500  3000  3500  4000  4500  5000  5500  6000\n",
      "  6500  7000  7500  8000  8500  9000  9500 10000 10500 11000 11500 12000\n",
      " 12500 13000 13500 14000 14500 15000]\n",
      "(30,) [-64.1 -99.  -99.  -99.  -99.  -99.  -99.  -99.  -99.  -99.  -99.  -99.\n",
      " -99.  -99.  -99.  -99.  -94.  -99.  -99.  -99.  -99.  -99.  -99.  -99.\n",
      " -94.  -99.  -99.  -99.  -99.  -94. ]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(f\"Changing to next lvl: 2 \\n\")\n",
    "\n",
    "trainer.change_env_dir(f\"train_games_lvl2\")\n",
    "eval_scores = trainer.train(\n",
    "    num_iterations=3000,\n",
    "    log_interval=250,\n",
    "    eval_interval=500,\n",
    "    game_gen_interval=500,\n",
    "    continue_training=True,\n",
    "    rndm_fill_replay=True,\n",
    "    plot_avg_ret=True,\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Changing to next lvl: 2 \n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ef865cce2090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchange_env_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"train_games_lvl2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m eval_scores = trainer.train(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/DeepLearningNLP/tf_train_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_iterations, train_interval, log_interval, eval_interval, game_gen_interval, continue_training, rndm_fill_replay, plot_avg_ret)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mexperience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tf_agents/agents/tf_agent.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, experience, weights, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m       loss_info = self._train_fn(\n\u001b[0m\u001b[1;32m    332\u001b[0m           experience=experience, weights=weights, **kwargs)\n\u001b[1;32m    333\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tf_agents/utils/common.py\u001b[0m in \u001b[0;36mwith_check_resource_vars\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# We're either in eager mode or in tf.function mode (no in-between); so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# autodep-like behavior is already expected of fn.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresource_variables_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMISSING_RESOURCE_VARIABLES_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tf_agents/agents/dqn/dqn_agent.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, experience, weights)\u001b[0m\n\u001b[1;32m    386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m       loss_info = self._loss(\n\u001b[0m\u001b[1;32m    389\u001b[0m           \u001b[0mexperience\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m           \u001b[0mtd_errors_loss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_td_errors_loss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tf_agents/agents/dqn/dqn_agent.py\u001b[0m in \u001b[0;36m_loss\u001b[0;34m(self, experience, td_errors_loss_fn, gamma, reward_scale_factor, weights, training)\u001b[0m\n\u001b[1;32m    457\u001b[0m       \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_q_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m       next_q_values = self._compute_next_q_values(\n\u001b[0m\u001b[1;32m    460\u001b[0m           next_time_steps, policy_steps.info)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tf_agents/agents/dqn/dqn_agent.py\u001b[0m in \u001b[0;36m_compute_next_q_values\u001b[0;34m(self, next_time_steps, info)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0;31m# Find the greedy actions using our target greedy policy. This ensures that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;31m# action constraints are respected and helps centralize the greedy logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m     greedy_actions = self._target_greedy_policy.action(\n\u001b[0m\u001b[1;32m    569\u001b[0m         next_time_steps, dummy_state).action\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tf_agents/policies/tf_policy.py\u001b[0m in \u001b[0;36maction\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_automatic_state_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m       \u001b[0mpolicy_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_reset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclip_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tf_agents/utils/common.py\u001b[0m in \u001b[0;36mwith_check_resource_vars\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# We're either in eager mode or in tf.function mode (no in-between); so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# autodep-like behavior is already expected of fn.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresource_variables_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMISSING_RESOURCE_VARIABLES_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tf_agents/policies/tf_policy.py\u001b[0m in \u001b[0;36m_action\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    558\u001b[0m     \"\"\"\n\u001b[1;32m    559\u001b[0m     \u001b[0mseed_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeedStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msalt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tf_agents_tf_policy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m     \u001b[0mdistribution_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_state\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=wrong-arg-types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m     actions = tf.nest.map_structure(\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreparameterized_sampling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tf_agents/policies/greedy_policy.py\u001b[0m in \u001b[0;36m_distribution\u001b[0;34m(self, time_step, policy_state)\u001b[0m\n\u001b[1;32m     78\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mDeterministicWithLogProb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgreedy_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     distribution_step = self._wrapped_policy.distribution(\n\u001b[0m\u001b[1;32m     81\u001b[0m         time_step, policy_state)\n\u001b[1;32m     82\u001b[0m     return policy_step.PolicyStep(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tf_agents/policies/tf_policy.py\u001b[0m in \u001b[0;36mdistribution\u001b[0;34m(self, time_step, policy_state)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_automatic_state_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m       \u001b[0mpolicy_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_reset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memit_log_probability\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m       \u001b[0;31m# This here is set only for compatibility with info_spec in constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tf_agents/policies/q_policy.py\u001b[0m in \u001b[0;36m_distribution\u001b[0;34m(self, time_step, policy_state)\u001b[0m\n\u001b[1;32m    151\u001b[0m           network_observation)\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     q_values, policy_state = self._q_network(\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mnetwork_observation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         step_type=time_step.step_type)\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tf_agents/networks/network.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m       \u001b[0mnormalized_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"network_state\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnormalized_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     nest_utils.assert_matching_dtypes_and_inner_shapes(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/DeepLearningNLP/agents/hub_policy.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, observation, network_state, training)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mflattened_observation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mencoder_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_preprocess_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_observation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Behave like BatchNormalization. (Dropout is different, b/181839368.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m       result = smart_cond.smart_cond(training,\n\u001b[0m\u001b[1;32m    238\u001b[0m                                      \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                                      lambda: f(training=False))\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     return control_flow_ops.cond(pred, true_fn=true_fn, false_fn=false_fn,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    237\u001b[0m       result = smart_cond.smart_cond(training,\n\u001b[1;32m    238\u001b[0m                                      \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                                      lambda: f(training=False))\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;31m# Unwrap dicts returned by signatures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_call_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f\"Changing to next lvl: 3 \\n\")\n",
    "\n",
    "trainer.change_env_dir(f\"train_games_lvl3\")\n",
    "eval_scores = trainer.train(\n",
    "    num_iterations=4000,\n",
    "    log_interval=250,\n",
    "    eval_interval=500,\n",
    "    game_gen_interval=500,\n",
    "    continue_training=True,\n",
    "    rndm_fill_replay=True,\n",
    "    plot_avg_ret=True,\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Changing to next lvl: 3 \n",
      "\n",
      "step = 250: loss = 1.10e+06, Buff-len = 17589\n",
      "step = 500: loss = 9.43e+05, Buff-len = 18341\n",
      "step = 500: Average Return = 51.1\n",
      "step = 750: loss = 4.74e+05, Buff-len = 19058\n",
      "step = 1000: loss = 8.19e+05, Buff-len = 19804\n",
      "step = 1000: Average Return = 51.0\n",
      "step = 1250: loss = 1.04e+06, Buff-len = 20584\n",
      "step = 1500: loss = 9.13e+05, Buff-len = 21334\n",
      "step = 1500: Average Return = 51.2\n",
      "step = 1750: loss = 1.20e+06, Buff-len = 22075\n",
      "step = 2000: loss = 1.05e+06, Buff-len = 22812\n",
      "step = 2000: Average Return = 51.0\n",
      "step = 2250: loss = 1.24e+06, Buff-len = 23555\n",
      "step = 2500: loss = 1.86e+06, Buff-len = 24287\n",
      "step = 2500: Average Return = 51.1\n",
      "step = 2750: loss = 8.36e+05, Buff-len = 25027\n",
      "step = 3000: loss = 6.23e+05, Buff-len = 25797\n",
      "step = 3000: Average Return = 51.1\n",
      "step = 3250: loss = 1.85e+06, Buff-len = 26555\n",
      "step = 3500: loss = 2.75e+06, Buff-len = 27333\n",
      "step = 3500: Average Return = 51.2\n",
      "step = 3750: loss = 1.24e+06, Buff-len = 28120\n",
      "step = 4000: loss = 1.41e+06, Buff-len = 28865\n",
      "step = 4000: Average Return = 51.1\n",
      "(8,) [ 500 1000 1500 2000 2500 3000 3500 4000]\n",
      "(8,) [51.1 51.  51.2 51.  51.1 51.1 51.2 51.1]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer.change_env_dir(f\"train_games_lvl4\")\n",
    "eval_scores = trainer.train(\n",
    "    num_iterations=8000,\n",
    "    log_interval=250,\n",
    "    eval_interval=500,\n",
    "    game_gen_interval=500,\n",
    "    continue_training=True,\n",
    "    rndm_fill_replay=True,\n",
    "    plot_avg_ret=True,\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step = 250: loss = 1.28e+06, Buff-len = 29805\n",
      "step = 500: loss = 1.29e+06, Buff-len = 30539\n",
      "step = 500: Average Return = 51.0\n",
      "step = 750: loss = 1.51e+06, Buff-len = 31310\n",
      "step = 1000: loss = 1.14e+06, Buff-len = 32048\n",
      "step = 1000: Average Return = 51.1\n",
      "step = 1250: loss = 1.22e+06, Buff-len = 32835\n",
      "step = 1500: loss = 1.49e+06, Buff-len = 33601\n",
      "step = 1500: Average Return = 51.0\n",
      "step = 1750: loss = 1.60e+06, Buff-len = 34351\n",
      "step = 2000: loss = 1.13e+06, Buff-len = 35087\n",
      "step = 2000: Average Return = 51.0\n",
      "step = 2250: loss = 1.13e+06, Buff-len = 35862\n",
      "step = 2500: loss = 1.24e+06, Buff-len = 36601\n",
      "step = 2500: Average Return = 51.1\n",
      "step = 2750: loss = 1.04e+06, Buff-len = 37354\n",
      "step = 3000: loss = 1.45e+06, Buff-len = 38084\n",
      "step = 3000: Average Return = 51.1\n",
      "step = 3250: loss = 1.45e+06, Buff-len = 38809\n",
      "step = 3500: loss = 1.43e+06, Buff-len = 39566\n",
      "step = 3500: Average Return = 51.1\n",
      "step = 3750: loss = 1.63e+06, Buff-len = 40267\n",
      "step = 4000: loss = 1.82e+06, Buff-len = 41004\n",
      "step = 4000: Average Return = 51.0\n",
      "step = 4250: loss = 9.50e+05, Buff-len = 41763\n",
      "step = 4500: loss = 1.47e+06, Buff-len = 42534\n",
      "step = 4500: Average Return = 51.0\n",
      "step = 4750: loss = 1.28e+06, Buff-len = 43279\n",
      "step = 5000: loss = 1.61e+06, Buff-len = 44023\n",
      "step = 5000: Average Return = 51.1\n",
      "step = 5250: loss = 1.64e+06, Buff-len = 44794\n",
      "step = 5500: loss = 1.46e+06, Buff-len = 45562\n",
      "step = 5500: Average Return = 51.0\n",
      "step = 5750: loss = 9.80e+05, Buff-len = 46334\n",
      "step = 6000: loss = 1.04e+06, Buff-len = 47065\n",
      "step = 6000: Average Return = 51.1\n",
      "step = 6250: loss = 1.14e+06, Buff-len = 47834\n",
      "step = 6500: loss = 1.25e+06, Buff-len = 48561\n",
      "step = 6500: Average Return = 51.0\n",
      "step = 6750: loss = 8.45e+05, Buff-len = 49312\n",
      "step = 7000: loss = 9.33e+05, Buff-len = 50086\n",
      "step = 7000: Average Return = 51.2\n",
      "step = 7250: loss = 9.29e+05, Buff-len = 50801\n",
      "step = 7500: loss = 1.27e+06, Buff-len = 51552\n",
      "step = 7500: Average Return = 51.1\n",
      "step = 7750: loss = 1.04e+06, Buff-len = 52304\n",
      "step = 8000: loss = 9.90e+05, Buff-len = 53052\n",
      "step = 8000: Average Return = 51.0\n",
      "(16,) [ 500 1000 1500 2000 2500 3000 3500 4000 4500 5000 5500 6000 6500 7000\n",
      " 7500 8000]\n",
      "(16,) [51.  51.1 51.  51.  51.1 51.1 51.1 51.  51.  51.1 51.  51.1 51.  51.2\n",
      " 51.1 51. ]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('tensorflow': conda)"
  },
  "interpreter": {
   "hash": "045652b23767f21ff8283538b8df83eae70d2472958a2d91a3594e31590cdc5c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}