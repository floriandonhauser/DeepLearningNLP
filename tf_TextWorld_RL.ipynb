{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "colab": {
   "name": "tf_TextWorld_RL.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Advanced Deep Learning for NLP - Text based adventure game RL\n"
   ],
   "metadata": {
    "id": "VJQwRDYVlPwi"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "WIP: Links not assigned yet\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/agents/blob/master/docs/tutorials/1_dqn_tutorial.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/agents/blob/master/docs/tutorials/1_dqn_tutorial.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ],
   "metadata": {
    "id": "LPNo9umRmNlr"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Google Colab stuff"
   ],
   "metadata": {
    "id": "2BDIAa_mlcXp"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%%capture\n",
    "!pip install tf-agents\n",
    "!pip install textworld\n",
    "!pip install -q -U tensorflow-text\n",
    "!pip install tensorflow-text\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/DeepLearningNLP/\")"
   ],
   "outputs": [],
   "metadata": {
    "id": "hXImSpAcBqWk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628005728288,
     "user_tz": -120,
     "elapsed": 13321,
     "user": {
      "displayName": "Max Lamparth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GggONWhA_LZZ2SpKMaopk7rlmYZrhiQrouD31deaw=s64",
      "userId": "07608444463794873074"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or alternatively (for future, when project not private anymore):"
   ],
   "metadata": {
    "id": "UkpwpO2ll8md"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "!git clone https://github.com/"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'github.com'...\n",
      "fatal: repository 'https://github.com/' not found\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z9iV-qUKmCpJ",
    "outputId": "65436aed-a27c-4ed5-fc23-278458003497"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "id": "4ge9lm5ElgBF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from resources import DEFAULT_PATHS\n",
    "# from tests import test_environment_creation\n",
    "\n",
    "from tf_train_loop import TWTrainer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {
    "id": "85h9Bei-n_al",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628005733664,
     "user_tz": -120,
     "elapsed": 5389,
     "user": {
      "displayName": "Max Lamparth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GggONWhA_LZZ2SpKMaopk7rlmYZrhiQrouD31deaw=s64",
      "userId": "07608444463794873074"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate games\n",
    "\n",
    "\n",
    "Generate simple debug game and large dataset of train and eval games."
   ],
   "metadata": {
    "id": "LpLGgA5Xk2NE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.chdir(\"/content/drive/MyDrive/DeepLearningNLP/scripts/\")"
   ],
   "outputs": [],
   "metadata": {
    "id": "svdyaH5irbYK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Will create single debug game. This is necessary."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%shell\n",
    "bash ./make_debug_game.sh"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Global seed: 2021\n",
      "Game generated: /content/drive/My Drive/DeepLearningNLP/resources/game_th_lvl2_simple.ulx\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 4
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMXxZfzGk_fV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627671800034,
     "user_tz": -120,
     "elapsed": 5099,
     "user": {
      "displayName": "Max Lamparth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GggONWhA_LZZ2SpKMaopk7rlmYZrhiQrouD31deaw=s64",
      "userId": "07608444463794873074"
     }
    },
    "outputId": "f7f54138-bacb-40b1-c461-694920680ed9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Only run this if necessary. Depending on system will take hours."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%capture\n",
    "%%shell\n",
    "bash ./make_allgames.sh"
   ],
   "outputs": [],
   "metadata": {
    "id": "tc9fq9C8n9q1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.chdir(\"/content/drive/MyDrive/DeepLearningNLP/\")"
   ],
   "outputs": [],
   "metadata": {
    "id": "bX23AdS2riOI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test environment"
   ],
   "metadata": {
    "id": "i2kCbHw2QeVX"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#test_environment_creation()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'test_environment_creation' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-41e0fc197a93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_environment_creation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_environment_creation' is not defined"
     ]
    }
   ],
   "metadata": {
    "id": "HawL9R4V6AYJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "id": "u1Zx2a9AQoVh"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set rewards for training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "REWARD_DICT = {\n",
    "    \"win_lose_value\": 100,\n",
    "    \"max_loop_pun\": 0,\n",
    "    \"change_reward\": 1,\n",
    "    \"useless_act_pun\": 1,\n",
    "    \"verb_in_adm\": 1,\n",
    "}"
   ],
   "outputs": [],
   "metadata": {
    "id": "fXTkK8pKyVX3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628005733666,
     "user_tz": -120,
     "elapsed": 16,
     "user": {
      "displayName": "Max Lamparth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GggONWhA_LZZ2SpKMaopk7rlmYZrhiQrouD31deaw=s64",
      "userId": "07608444463794873074"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Try overfitting on one debug game (correct command \"take x\" will immediately win or lose the game).\n",
    "Depending on whether random agent finds correct WIN command, number of iterations will be enough or not.\n"
   ],
   "metadata": {
    "id": "mh1VFswxyBw9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "DEFAULT_HP = {\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"initial_collect_steps\": 2000,\n",
    "    \"collect_steps_per_iteration\": 1,\n",
    "    \"replay_buffer_max_length\": 100000,\n",
    "    # large values lead to OOM with bert policy\n",
    "    \"batch_size\": 32,\n",
    "    \"num_eval_episodes\": 1,\n",
    "    \"game_gen_buffer\": 25,\n",
    "    \"num_eval_games\": 5,\n",
    "}\n",
    "trainer = TWTrainer(\n",
    "    reward_dict=REWARD_DICT,\n",
    "    hpar=DEFAULT_HP,\n",
    "    debug=False,\n",
    "    biased_buffer=True,\n",
    "    # embedding into fc is default policy\n",
    "    # agent_label=\"FCPolicy\",\n",
    "    agent_label=\"BertPolicy\",\n",
    ")\n",
    "eval_scores = trainer.train(\n",
    "    num_iterations=500,\n",
    "    log_interval=25,\n",
    "    eval_interval=25,\n",
    "    game_gen_interval=500,\n",
    "    plot_avg_ret=True,\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "log can be found in/home/florian/Documents/DeepLearningNLP/resources/logdir/20210804-145945\n",
      "WARNING:tensorflow:From /home/florian/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:382: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:From /home/florian/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:382: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/florian/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:From /home/florian/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step = 25: loss = 8.28e+01, Buff-len = 104\n",
      "step = 25: Average Return = 51.0\n",
      "step = 50: loss = 1.99e+02, Buff-len = 187\n",
      "step = 50: Average Return = 51.0\n",
      "step = 75: loss = 4.08e+02, Buff-len = 258\n",
      "step = 75: Average Return = 50.0\n",
      "step = 100: loss = 1.21e+03, Buff-len = 306\n",
      "step = 100: Average Return = 51.0\n",
      "step = 125: loss = 4.60e+03, Buff-len = 379\n",
      "step = 125: Average Return = 51.0\n",
      "step = 150: loss = 1.17e+04, Buff-len = 445\n",
      "step = 150: Average Return = 51.0\n",
      "step = 175: loss = 6.57e+03, Buff-len = 507\n",
      "step = 175: Average Return = 50.0\n",
      "step = 200: loss = 1.93e+04, Buff-len = 569\n",
      "step = 200: Average Return = 50.0\n",
      "step = 225: loss = 1.03e+04, Buff-len = 647\n",
      "step = 225: Average Return = 51.0\n",
      "step = 250: loss = 2.22e+04, Buff-len = 718\n",
      "step = 250: Average Return = 50.0\n",
      "step = 275: loss = 3.23e+04, Buff-len = 786\n",
      "step = 275: Average Return = 51.0\n",
      "step = 300: loss = 3.39e+04, Buff-len = 858\n",
      "step = 300: Average Return = 51.0\n",
      "step = 325: loss = 1.00e+05, Buff-len = 926\n",
      "step = 325: Average Return = 51.0\n",
      "step = 350: loss = 1.28e+05, Buff-len = 989\n",
      "step = 350: Average Return = 50.0\n",
      "step = 375: loss = 1.59e+05, Buff-len = 1074\n",
      "step = 375: Average Return = 51.0\n",
      "step = 400: loss = 1.08e+05, Buff-len = 1141\n",
      "step = 400: Average Return = 50.0\n",
      "step = 425: loss = 3.39e+05, Buff-len = 1218\n",
      "step = 425: Average Return = 50.0\n",
      "step = 450: loss = 1.65e+05, Buff-len = 1299\n",
      "step = 450: Average Return = 50.0\n",
      "step = 475: loss = 1.78e+05, Buff-len = 1376\n",
      "step = 475: Average Return = 50.0\n",
      "step = 500: loss = 3.06e+05, Buff-len = 1446\n",
      "step = 500: Average Return = 50.0\n",
      "(20,) [ 25  50  75 100 125 150 175 200 225 250 275 300 325 350 375 400 425 450\n",
      " 475 500]\n",
      "(20,) [51. 51. 50. 51. 51. 51. 50. 50. 51. 50. 51. 51. 51. 50. 51. 50. 50. 50.\n",
      " 50. 50.]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {
    "id": "LL2l3YVFyKoM",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628006427910,
     "user_tz": -120,
     "elapsed": 607599,
     "user": {
      "displayName": "Max Lamparth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GggONWhA_LZZ2SpKMaopk7rlmYZrhiQrouD31deaw=s64",
      "userId": "07608444463794873074"
     }
    },
    "outputId": "e4aa2440-49d6-4c88-dc5d-581bb549c674"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Activate TensorBoard logging."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pathdir = DEFAULT_PATHS[\"path_logdir\"]\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $pathdir"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "TZMwAYvxQ36g",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1628004969602,
     "user_tz": -120,
     "elapsed": 9,
     "user": {
      "displayName": "Max Lamparth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GggONWhA_LZZ2SpKMaopk7rlmYZrhiQrouD31deaw=s64",
      "userId": "07608444463794873074"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train on all four levels with (simple) Embedding-FC policy agent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "DEFAULT_HP = {\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"initial_collect_steps\": 10000,\n",
    "    \"collect_steps_per_iteration\": 1,\n",
    "    \"replay_buffer_max_length\": 100000,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_eval_episodes\": 1,\n",
    "    \"game_gen_buffer\": 25,\n",
    "    \"num_eval_games\": 10,\n",
    "}\n",
    "\n",
    "trainer = TWTrainer(\n",
    "    env_dir=\"train_games_lvl1\",\n",
    "    reward_dict=REWARD_DICT,\n",
    "    hpar=DEFAULT_HP,\n",
    "    debug=False,\n",
    "    biased_buffer=True,\n",
    "    # embedding into fc is default policy\n",
    "    agent_label=\"FCPolicy\",\n",
    "    # agent_label=\"BertPolicy\",\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'TWTrainer' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c730ab9df5cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m trainer = TWTrainer(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0menv_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_games_lvl1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mreward_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREWARD_DICT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TWTrainer' is not defined"
     ]
    }
   ],
   "metadata": {
    "id": "s-LGSOqOmx08"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print(f\"Starting with lvl: 1 \\n\")\n",
    "\n",
    "eval_scores = trainer.train(\n",
    "    num_iterations=3000,\n",
    "    log_interval=250,\n",
    "    eval_interval=500,\n",
    "    game_gen_interval=500,\n",
    "    rndm_fill_replay=True,\n",
    "    plot_avg_ret=True,\n",
    ")\n",
    "\n",
    "print(f\"Changing to next lvl: 2 \\n\")\n",
    "\n",
    "trainer.change_env_dir(f\"train_games_lvl2\")\n",
    "eval_scores = trainer.train(\n",
    "    num_iterations=3000,\n",
    "    log_interval=250,\n",
    "    eval_interval=500,\n",
    "    game_gen_interval=500,\n",
    "    continue_training=True,\n",
    "    rndm_fill_replay=True,\n",
    "    plot_avg_ret=True,\n",
    ")\n",
    "\n",
    "print(f\"Changing to next lvl: 3 \\n\")\n",
    "\n",
    "trainer.change_env_dir(f\"train_games_lvl3\")\n",
    "eval_scores = trainer.train(\n",
    "    num_iterations=4000,\n",
    "    log_interval=250,\n",
    "    eval_interval=500,\n",
    "    game_gen_interval=500,\n",
    "    continue_training=True,\n",
    "    rndm_fill_replay=True,\n",
    "    plot_avg_ret=True,\n",
    ")\n",
    "\n",
    "print(f\"Changing to next lvl: 4 \\n\")\n",
    "\n",
    "trainer.change_env_dir(f\"train_games_lvl4\")\n",
    "eval_scores = trainer.train(\n",
    "    num_iterations=8000,\n",
    "    log_interval=250,\n",
    "    eval_interval=500,\n",
    "    game_gen_interval=500,\n",
    "    continue_training=True,\n",
    "    rndm_fill_replay=True,\n",
    "    plot_avg_ret=True,\n",
    ")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting with lvl: 1 \n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-85a04a75f18a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Starting with lvl: 1 \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m eval_scores = trainer.train(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "LYD27Tn7_h3u"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyper parameter search\n",
    "\n",
    "Simple hyper parameter search.\n",
    "\n",
    "CODE OUT OF DATE. Still used old train method."
   ],
   "metadata": {
    "id": "izOrJDtvs4rO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%capture\n",
    "!pip install optuna\n",
    "import optuna"
   ],
   "outputs": [],
   "metadata": {
    "id": "A4S3R9tSqH-c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    hp_dict = {\n",
    "      \"num_iterations\": 2000,\n",
    "      \"learning_rate\": trial.suggest_loguniform(\"lr\", 1e-4, 1e-2),\n",
    "      \"initial_collect_steps\": 10000,\n",
    "      \"collect_steps_per_iteration\": 1,\n",
    "      \"replay_buffer_max_length\": 100000,\n",
    "      \"batch_size\": trial.suggest_int(\"batch_size\", 16, 256),\n",
    "      \"log_interval\": 500,\n",
    "      \"num_eval_episodes\": 1,\n",
    "      \"eval_interval\": 100,\n",
    "    }\n",
    "\n",
    "    REWARD_DICT = {\n",
    "        \"win_lose_value\": 100,\n",
    "        \"max_loop_pun\": 1,\n",
    "        \"change_reward\": 1,\n",
    "        \"useless_act_pun\": 1,\n",
    "        \"verb_in_adm\": 1,\n",
    "    }\n",
    "\n",
    "    eval_scores = train.main(plot_avg_ret=True, debug=False, reward_dict=REWARD_DICT, **hp_dict)\n",
    "    # eval_scores = np.delete(eval_scores, 0)\n",
    "\n",
    "    return max(eval_scores)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "print(study.best_trial)"
   ],
   "outputs": [],
   "metadata": {
    "id": "DQlG-WJQs74O"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(study.best_trial)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FrozenTrial(number=0, values=[203.0], datetime_start=datetime.datetime(2021, 7, 30, 11, 46, 26, 924586), datetime_complete=datetime.datetime(2021, 7, 30, 11, 50, 2, 140224), params={'lr': 0.004015582546958087, 'batch_size': 89}, distributions={'lr': LogUniformDistribution(high=0.01, low=0.0001), 'batch_size': IntUniformDistribution(high=256, low=16, step=1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=0, state=TrialState.COMPLETE, value=None)\n"
     ]
    }
   ],
   "metadata": {
    "id": "SeEcJWtgumr7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1627651497254,
     "user_tz": -120,
     "elapsed": 385,
     "user": {
      "displayName": "Max Lamparth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GggONWhA_LZZ2SpKMaopk7rlmYZrhiQrouD31deaw=s64",
      "userId": "07608444463794873074"
     }
    },
    "outputId": "f790496d-7644-44f4-af65-3cc27a28e14a"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "id": "KKFKyzX-ltnR"
   }
  }
 ]
}